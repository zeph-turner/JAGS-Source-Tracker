---
title: "JSG Functions Vignette"
author: "Zeph Turner"
date: "April 21, 2018"
output: html_document
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE,warning=FALSE, error=FALSE, message=TRUE)
options(digits=2)
library(readr)
library(dplyr)

#Set working directory to JAGS-Source-Tracker folder
#Change this path before starting
setwd("~/GitHub/JAGS-Source-Tracker")
set.seed(1083535)
```

##Setup

To be able to access these functions from an R script, first source the document to load the functions.

```{r}
fileroot <- getwd()
source(paste0(fileroot, "/jsg_functions.R"))
```

The setup() function loads a handful of libraries into the R environment. rjags, reshape2, and mosaic should all be installed via install.packages before this is run. 

```{r}
setup()
```

##Create Data

The create_data() function randomly generates an OTU table and map meeting user specifications. This is useful for testing the software and experimenting with its accuracy on datasets where the sources are more or less difficult to distinguish. 

It takes a number of inputs:

- nSink: Number of sink samples to generate.
- nSource: Number of source samples to generate.
- nOTU=20: Number of OTUs to generate for sink and source sample.
- drawFromKnown = TRUE: Should the sink sample be drawn from a generated source sample, or randomly generated from a simulated "unknown" source (not inclued in the source data)? Note: This function is not yet fully functional; this works, but it's not accounted for in the output true_sources map.
- sparsity = 0.1: The source data is "sparisified" by setting this proportion of OTUs to 0 before drawing sink samples.
- moreThanOne=TRUE: Should each sink sample be drawn from one source, or more than one source? If this is true, the sink sample will be drawn from at least 1 and at most nSource sources. The exact number is random.
- highOTU=500: Each source has an assigned high OTU set to this count to distinguish it from other sources.
- lowOTU=400: All other OTUs (besides each source's high OTU) are set to a count *around* this number. Actual counts are generated by drawing a total of lowOTU*(nOTU-1) OTUs from a multinomial distribution.

```{r}
set.seed(1083535)
this <- create_data(1, 5, 20, TRUE, 0.2, FALSE, 50, 45)
```

create_data() returns an object with three parts: an OTU table, a "map" identifying which columns are sink and which are source samples, and the true sources matrix, which specifies the actual sources of each sink in the sample.

The OTU table looks like this:

```{r}
head(this$otu_table)
```

The map looks like this:

```{r}
this$map
```

The "Env" variable is not accessed automatically by any functions, but it can be used to "pool" source or sink samples that come from the same environment if desired.

Lastly, the true sources matrix looks like this:

```{r}
this$trueSources
```

This indicates that the sink sample was drawn from source 4. Sink samples correspond to rows and source samples are columns.

When running real data through JSG, the user will need to ensure that the OTU table is formatted like the one above (OTUs are rows; samples are columns with a unique Sample ID as the header). They will also need to provide or alter a metadata map to have columns SampleID and SourceSink specifying the unique sample ID and whether it is to be treated as a source or a sink, respectively. The permissible inputs in the SourceSink column are only "Source" and "Sink". 

##Write OTU Table

To save a simulated OTU table, the write_otu_table function is available.

```{r}
#Update filename before running.
filename = paste0(fileroot, "/otu_table_example.csv")
write_otu_table(this$otu_table, 1, 5, filename)
```

##Estimate Proportions

Finally, with all these components, we are ready to estimate the sources of the sink samples.

The input OTU table must be formatted as shown above, with OTUs arranged as rows and samples as columns headed by a unique sample ID. To import an OTU table from a .biom file, the following commands can be used. (Example .biom file and metadata map are from http://qiime.org/1.5.0/documentation/file_formats.html .)

```{r}
#Load the phyloseq library to handle .biom files.
library(phyloseq)

#Save the file path to the .biom file to a variable.
example_biom = paste0(fileroot, "/example_biom_data/example_otu_table.biom")

#Import the .biom file into R using the file path.
example = import_biom(example_biom, parseFunction=parse_taxonomy_default)

#Extract the OTU table to a separate variable.
example_otus <- otu_table(example)

#Finalized OTU table. It can be indexed into just like any other table using [row, column] indexing.
#The OTU table can be passed to estimate_proportions in this format.
example_otus[414:419,]
```

This will give an OTU table in the proper format to be fed into JAGS.

The map used can be adapted from metadata for the samples; the map is essentially a specialized metadata file. As described previously, it should have columns SampleID and SourceSink specifying the unique sample ID and whether it is to be treated as a source or a sink, respectively. The SampleID column may have to be renamed (commonly it is named '#SampleID', which R doesn't like). The SourceSink column must be added to tell JAGS what to treat as the source and sink samples. The SourceSink column will usually be created based on other metadata attributes -- for example, below, samples are assigned "source" or "sink" based on whether or not they are samples from the control group or the treatment group fo a mouse study.


```{r}
#Read first metadata table.
Metadata <- read_table2(paste0(fileroot, "/example_biom_data/metadata_map.txt"))

#Assign source and sink samples based on metadata attributes.
Metadata <- mutate(Metadata, SourceSink=ifelse(Metadata$Treatment == "Control", "sink", "source"))

#Rename "#SampleID" to "SampleID" (R doesn't like pound signs in variable names)
colnames(Metadata)[1] <- "SampleID"

#Finished map
Metadata
```

To finish processing the data, the metadata and OTU tables passed to estimate_proportions should only contain the necessary rows and columns: The map should only contain the IDs of samples we are using for estimation. The OTU table should also contain only columns for samples used for estimation. (Extra columns in the OTU table should not cause an error, but the software will use *all* sources and sinks specified in the map for estimation, so if there are extra rows in the map, the software may end up running more data than desired.) The following commands trim out unnecessary rows and columns. After this, Metadata_subs and otu_subs are ready to be passed to estimate_proportions.

```{r}
Metadata_subs <- Metadata[5:6,]

otu_subs <- example_otus[,Metadata_subs$SampleID]
```

Below is an example of estimate_proportions run on our fake, generated OTU table and map that we made using create_data earlier. 

The parameters for estimate_proportions are:

- OTU table in column-as-sample format
- Metadata map with SampleID and SourceSink columns correctly populated
- Number of sink samples
- Number of source samples
- Number of unknown sources to use (default: 0)
- Number of Monte-Carlo Markov chains to generate (default: 4)
- Number of adaptation steps to run before beginning burn-in (default: 500)
- Number of burn-in steps to run before beginning sampling (defulat: 500)
- Number of samples to generate from the posterior distribution per chain (default: 500)
- alpha, the prior count of taxa in each source (default: 0.1)
- beta, the prior count of taxa from each source in the sink (default: 0.1)

```{r}
samples <- estimate_proportions(this$otu_table, this$map, 1, 5, 1, chains=3, 
                                  adapt=500, burnin=500, samplesPerChain=500,
                                  alpha=.1, beta=.1)
```

This command produces some useful console output. First is the source guide: In the output sample of source proportion vectors, the sources will be numbered, *not* labeled by unique sample ID. The "Source Guide" output conveniently matches those numbers to unique sample IDs. JAGS also produces its own output showing the progress of initializing and running the model. 

The output, "samples", is actually a list of lists, where each list contains the samples from the posterior source vector distribution of one sink sample. The output "Saving 7 in 1" means that the posterior distribution for the sink sample in column 7 of the OTU table lives in the first list in the list of lists, samples[[1]]. 

The "number of items to replace is not a multiple of replacement length" warning is normal and can be ignored.

```{r}
head(samples[[1]])
```

samples[[1]] contains 500 samples from the posterior distribution of the source vector. Note that B[[1]] corresponds to source number 1 in the source guide, B[[2]] corresponds to source number 2, etc. In this case we only have one posterior distribution since we had only one sink sample, but if there were a second sink sample, that output would be stored in samples[[2]] and could be accessed in the same way.

It is usually advantageous to cast each of these lists to matrices where each column is a source and each row is a source proportion vector.

```{r}
nSource <- 5
nUnknown <- 1
samplepost <- matrix(samples[[1]], ncol=(nSource+nUnknown))
head(samplepost)
```

Then we can summarize the results: 

```{r}
samplepost.df <- as.data.frame(samplepost)
colnames(samplepost.df) <- paste("Source", 1:(nSource+nUnknown))

#Output mean source proportions
summarise_all(samplepost.df, funs(mean))

#Output median source proportions
summarise_all(samplepost.df, funs(median))
```

The output correctly estimates that this sample was drawn from source 4.

To estimate proportions for the real OTU table, first select only the sources and sinks you want to use for estimation from the OTU table. Then pass the map with "SourceSink" and "SampleID" columns along with the subset of the OTU table to estimate_proportions. Referencing the source guide, we can see that the program estimates that almost none of the sink sample came from the source sample.

```{r}
otu_samples <- estimate_proportions(otu_subs, Metadata_subs, 1, 1, 1, chains=3, 
                                  adapt=500, burnin=500, samplesPerChain=500,
                                  alpha=.1, beta=.1)
otu_samplepost <- matrix(otu_samples[[1]], ncol=(2))
otu_samplepost.df <- as.data.frame(otu_samplepost)
summarise_all(otu_samplepost.df, funs(median))
```

##Creating Violin and Boxplots

There are two functions included for visually depicting results, print_violinplots and print_boxplots. Each take samples, the output of estimate_sources, as their input, along with the number of sink, source, and unknown columns.

```{r}
#Parameters: Number of sinks, number of sources, number of unknowns, 
# and the output from estimate_proportions.
#If there are multiple sink sources, this will create a separate violin plot
#for each of them.
print_violinplots(1, 5, 1, samples)
```

```{r}
#Same parameters; only difference is that boxplots are printed.
print_boxplots(1, 5, 1, samples)
```

These functions are good for an overall view of the data, but the samples data can be used directly for data visualization as well. This would be helpful in this scenario: we could leave out the box or violin plot showing proportion of source 4 in the sample and therefore be better able to see the proportions of other samples, or we could view only the estimated proportion of source 4.